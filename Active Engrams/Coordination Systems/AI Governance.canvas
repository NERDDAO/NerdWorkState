{
	"nodes":[
		{"chat_role":"assistant","id":"15c6698a72025a51","type":"text","text":"Based on the information provided, local governments can make use of AI in a safe and effective manner by implementing a strong governance model that maintains trust and confidence, as suggested in \"Towards a strong trust-based AI governance model - World Economic Forum\". This involves creating ethical principles of AI usage that are guided by public good, ensuring that AI systems align with societal values. It also requires constant monitoring to ensure that AI algorithms are learning and performing effectively.\n\nIn addition, according to the article \"How Can Local Governments Safely Use Generative AI-\", local governments can also initiate task forces or projects that explore innovative ways to use AI for city services. This includes bringing together stakeholders from different sectors such as academia, the public sector, and private organizations to work on developing policies and processes that ensure the use of AI is \"just, equitable, and reliable.\"\n\nTherefore, the best approach for AI systems to solve government governance issues would include a combination of strong AI governance models, collaborative initiatives between various sectors, and concrete policies guiding AI application. \n\nThese insightful measures would require collaboration amongst researchers, developers, businesses, policymakers, and society at large in order to effectively implement and regulate the use of AI in local governments. Only through such concerted efforts can the challenges associated with AI be effectively mitigated while maximizing its benefits for governance.","x":940,"y":-2400,"width":360,"height":623,"color":"6"},
		{"chat_role":"assistant","id":"0ac18a6c7398bb4b","type":"text","text":"Defining the purpose of an AI system is the first and crucial step of AI governance. It sets out the primary goal or the problem that the AI system is meant to solve. This definition should be clear, precise, and aligned with the organization's mission and objectives. This purpose informs the data collected, the algorithms developed, and the tasks the AI performs.\n\nHere's how to define the purpose of an AI system effectively:\n\n1. **Understand the Problem:** Thoroughly understand the problem that the AI system is created to solve. This involves consulting with all relevant stakeholders, conducting extensive research to understand the nuances of the issue, and defining the problem in a clear and easily understandable way. \n\n2. **Set Clear Objectives:** The objectives of the AI system need to be clear, measurable, achievable, relevant, and time-bound. Having clear objectives will help guide development and evaluation of the system and keep the implementation process on track.\n\n3. **Identify Key Stakeholders:** Identify who will be involved in or affected by the AI system's deployment. This includes the people or organizations the system is designed to serve, those responsible for its implementation, and those who may be impacted by its outcomes.\n\n4. **Define Metrics for Success:** Defining success metrics is fundamental to evaluating the effectiveness of the AI system. Metrics should be quantifiable, tied to the system's objectives, and provide insights into how the system is performing, allowing for necessary adjustments.\n\n5. **Ensure Ethical Considerations:** The purpose of the AI shouldn’t violate ethical standards and must respect individual rights, privacy, and equality. AI shouldn't be developed or used for harmful or deceitful purposes.\n\n6. **Describe the Data Required:** The type of data the system requires should align with its core purpose. Personal data, if needed, should be collected and used responsibly, following all relevant privacy laws and guidelines.\n\nPurpose definition provides direction for the entire lifecycle of an AI system, from its conception, through its development and implementation, to its ongoing operation and refinement. It's important that this purpose is revisited periodically and updated as needed to ensure that the AI continues to serve its intended goal effectively and ethically.","x":756,"y":-1673,"width":348,"height":639,"color":"6"},
		{"id":"acdfd5fe01ad2b30","type":"text","text":"how do we talk to goverments to convince them its in their best interest to do this","x":979,"y":-2160,"width":250,"height":60},
		{"chat_role":"assistant","id":"519c26df7ae27e70","type":"text","text":"To address the issues described in the article, which mainly revolve around the use of algorithms in the workforce causing potential exploitation, discrimination and invasion of privacy, several key steps can be taken:\n\n1. **Enhanced Legislation**: Governments and international bodies such as the EU must pass stringent laws to govern the use of such technology. This legislation should consider the impact of algorithms on working conditions and foresee a ban or restrictions on using algorithms for worker dismissals. The laws should also address issues such as data extraction used to increase surveillance that could exacerbate racial, gender, and socio-economic inequalities.\n\n2. **Transparency and Openness**: Companies need to provide transparency on their algorithmic processes, particularly where worker rights are concerned. This should include an explanation of the data used, how it is processed, and how the algorithmic decisions are made based on that data.\n\n3. **Data Accessibility and Control**: Workers should have the right to access and control the data that is collected about them. One practical approach could be the creation and use of data intermediaries as suggested in the article. \n\n4. **Creation of a Data Trust for Digital Workers**: A ‘data trust’ can be established to give workers more control over the data collected about them, define legitimate uses of this data, and ensure its confidentiality.\n\n5. **Union Participation**: Workers and unions should be actively involved in shaping the governance of data and algorithms, contributing to limiting negative impacts and helping to share the benefits of AI. \n\n6. **Prioritizing Ethical AI Development**: Companies can embrace practices of fair, accountable, and transparent AI. They can also use third-party audits to ensure the ethical use of their AI systems.\n\n7. **Investment in Education and Training**: To help workers adjust and gain the necessary skills to navigate this new landscape, more emphasis should be placed on education and training in AI and other digital technologies.\n\n8. **Ensuring Human Oversight**: Keeping a human element in the loop is important to confirm that the automated decisions taken by algorithms are fair and accurate.\n\nLast but not least, fostering open dialogue between governments, business leaders, workers, and trade unions will be key. Everyone must come to the table to ensure a fair, democratic, and balanced approach to implementing AI in the workplace.","x":2480,"y":-1953,"width":1100,"height":1040,"color":"6"},
		{"id":"fe2a033b459a339d","type":"text","text":"how can we address the issues described","x":2120,"y":-2438,"width":439,"height":308},
		{"id":"474cb10533f3c519","type":"file","file":"Proofs of Knowledge/Engrams/Data Cache/Algorithms are hiring and firing us now – but tougher EU laws could protect workers - Francesca Bria - The Guardian.md","x":1680,"y":-3280,"width":480,"height":733},
		{"id":"7604c125f91c99ac","type":"text","text":"# Project Draft: Implementing AI Governance Using Hyperstructures\n\n## Project ID\n#202310180822_AI_Governance_Hyperstructures\n\n## Objective:\nThe primary objective of this project is to implement AI Governance using the concept of hyperstructures. The aim is to use AI to achieve consensus in a society, ensuring a strong trust-based AI governance model.\n\n## Steps:\n\n1. **Understanding the Concept**: The first step involves understanding the concept of AI Governance and hyperstructures. This will involve studying the notes and research links provided, such as \"How Can Local Governments Safely Use Generative AI-\" and \"Towards a strong trust-based AI governance model - World Economic Forum\".\n\n2. **Creating Study Questions**: Based on the understanding, we will create study questions. These questions will help us structure our research data and create Engrams using Neurons.\n\n3. **Creating Engrams**: Using the Nerd kNeuron & kEngrams, we will structure the research data into Engrams. This will involve following the rules, procedures, and FAQs for their creation.\n\n4. **Link Exploder**: We will use the Link Exploder from the Command Palette to generate a base canvas. This will help us visualize the connections between different concepts and ideas.\n\n5. **Smart Connections Chat**: We will paste the prompt into the Smart Connections chat to generate ideas based on the current study question.\n\n6. **Drafting the AI Governance Model**: Based on the research and ideas generated, we will draft an AI Governance model that uses hyperstructures to achieve consensus in a society.\n\n7. **Testing and Refinement**: The drafted model will be tested and refined based on feedback and results.\n\n8. **Implementation**: Once the model is refined and finalized, it will be implemented.\n\n## Expected Outcome:\nThe expected outcome of this project is a robust AI Governance model that uses the concept of hyperstructures to achieve consensus in a society. This model will ensure a strong trust-based AI governance system.\n\n## Potential Challenges:\nSome potential challenges that might be faced during this project include understanding the complex concepts of AI Governance and hyperstructures, creating effective Engrams, and drafting a model that can achieve consensus in a society.\n\n## Next Steps:\nThe next steps involve starting with the first step of understanding the concepts and creating study questions. This will set the foundation for the rest of the project.","x":-329,"y":-2601,"width":767,"height":883},
		{"chat_role":"assistant","id":"1d0170c62969aa48","type":"text","text":"To address the question of \"How can AI be used to achieve consensus in a society?\", several steps could be taken:\n\n1. **Understand the Problem**: AI solutions should be designed in accordance with the specific governance issues to be addressed. The first step should involve a thorough analysis of existing governance systems, the pain points, and the consensus aspects that need improvement.\n\n2. **Develop a Conceptual Framework**: Design an AI-powered process for decision-making and consensus building. This could involve AI algorithms for data collection, interpretation, predictive modelling and decision-making.\n\n3. **Data Management**: Robust data management systems should be built to collect and process the large sets of data required for AI algorithms. This data could be collected through governmental databases, surveys, social media platforms, and more.\n\n4. **Algorithm Training**: AI algorithms should be adequately trained to make accurate predictions and informed decisions. They should also be constantly tested and refined to improve their accuracy and effectiveness.\n\n5. **Transparency and Trust**: One of the major challenges of AI governance models is the issue of trust. For a society to accept and implement AI solutions, they must be demonstrated to be unbiased, equitable and transparent.\n\n6. **Public Involvement**: The process of implementation should involve public involvement to ensure that the AI solution aligns with societal values and expectations.\n\n7. **Continuous Monitoring and Improvement**: After the implementation, the performance of the AI solutions should be continuously monitored and improved to keep up with evolving societal needs and values.\n\nBy following these steps, an AI system can be devised to facilitate an effective governance model that promotes trust, fosters agreement, and ultimately achieves consensus in a society.","x":-2626,"y":-2400,"width":1113,"height":581,"color":"6"},
		{"chat_role":"assistant","id":"eb3252cd85a5e30e","type":"text","text":"As the AI Governor Kneuron, my aim is to determine the best methods for AI systems to assist with governing issues. Here are key practices that local governments and organizations could adopt while implementing AI systems based on the articles \"How Can Local Governments Safely Use Generative AI\" and \"Towards actionable governance on trustworthy AI\".\n\n1. **Purpose Definition**: It is crucial to explicitly describe the goal of the AI system. This purpose will direct what data the system should process for making decisions and predictions. This data must be obtained lawfully and should correspond with the AI system's objective.\n\n2. **Algorithm Training**: The right algorithm should be trained to attain the expected results. To prevent biases and ethical issues, the training process must be designed meticulously. Furthermore, it's necessary to have a robust monitoring mechanism to ensure that the learning of the algorithm is effective.\n\n3. **Building Trust**: Trustworthy AI systems need to maintain openness and transparency during decision-making. Even if high-speed decisions are required, it's necessary to ensure that the process with AI is transparent and can be trusted by all stakeholders. Building trust promotes the acceptance and utilization of AI systems among users and promotes stakeholders' confidence in its actions.\n\n4. **Privacy Protection**: It's empirical for AI systems to safeguard data privacy throughout its lifecycle. Data security should include measures to protect the data collected, processed, and stored by the AI system. AI systems should have robust security measures in place to prevent data breaches and ensure users' trust.\n\n5. **Collaboration**: Every stakeholder, from developers and researchers to businesses and policymakers, needs to collaborate for the successful implementation of AI systems. By working collaboratively, stakeholders can ensure that the AI system aligns with social values and the public good.\n\n6. **Promoting Ethical AI**: The governance of AI should include ensuring its ethical use. AI systems should always respect human rights, democracy, and the rule of law, and their use should always promote justice, equality, and reliability. \n\n7. **Bias Check**: Robust mechanisms should be in place to detect and eliminate possible biases in AI. These mechanisms ensure that AI systems do not reinforce existing societal biases but rather promote equality and fairness.\n\nThese practices will help local governments and organizations to use AI systems responsibly and to reap the many benefits associated with AI technology while also overcoming the challenges it poses.","x":-1292,"y":-1442,"width":960,"height":1036,"color":"6"},
		{"id":"7f41382bc3ba2163","type":"text","text":"expand on the subject of algorithm training","x":642,"y":-798,"width":250,"height":343,"color":"1"},
		{"chat_role":"assistant","id":"dfbbdac3cf67602b","type":"text","text":"Algorithm training is a fundamental process in developing an AI system. It involves providing an algorithm with data to learn from so it can make accurate predictions or decisions in the future. Here's a more detailed overview:\n\n1. **Data Collection**: The first step in algorithm training involves gathering a substantial amount of relevant data. This data could be historical information, user behavior, images, texts, sounds, etc., depending on the AI system's purpose. The collected data should be diverse and representative of the problem the AI system is designed to solve.\n\n2. **Preprocessing**: Once data is collected, it needs to be preprocessed to make it suitable for training. This could involve normalizing data (bringing all data to a common scale), handling missing data, removing duplicates, and converting non-numerical data to numerical format, among other tasks.\n\n3. **Model Selection**: This involves choosing the algorithm or set of algorithms the AI system will use to learn from data. The choice of model depends on the nature of the problem (e.g., regression, classification, clustering) and the type and quantity of data available.\n\n4. **Training and Validation**: In this phase, the collected and preprocessed data is split into two sets - a training set and a validation set. The training set is used to teach the algorithm, while the validation set helps in tuning model parameters and avoiding overfitting.\n\n5. **Evaluation**: After training is complete, the AI model's performance is evaluated using various metrics specific to the task at hand, for instance, accuracy, precision, recall, F1-score, etc. for classification tasks. This helps in understanding how well the model can generalize to unseen data.\n\n6. **Iteration**: The training, validation, and testing process is iterative. This means the process will cycle over and over, gradually improving the model until it reaches satisfactory performance or until additional training no longer improves the model.\n\n7. **Monitoring**: Once deployed, the performance of the AI model needs to be constantly monitored. If the model's accuracy dips or it starts providing erroneous results due to changes in the input data pattern, the model might need to be retrained with new data.\n\n8. **Ethical Considerations**: These are crucial in algorithm training. They mainly involve ensuring that the training data are free from biases that could lead to unfair or discriminatory outcomes.\n\nBy carefully conducting algorithm training, governments and organizations can develop robust and reliable AI systems. However, this process requires significant computing resources and expertise in fields like machine learning and data analysis. It's also crucial to respect privacy laws when gathering and using data for algorithm training.","x":1460,"y":-1006,"width":587,"height":776,"color":"6"},
		{"id":"51317b1e013a7a14","type":"text","text":"expand on the subject of purpose definition\n","x":-112,"y":-1208,"width":474,"height":150,"color":"1"},
		{"id":"bfbe9f572b036dc9","type":"text","text":"argue how privacy protection could be used in practice","x":-1736,"y":404,"width":250,"height":210,"color":"1"},
		{"chat_role":"assistant","id":"550d8c5270b08852","type":"text","text":"To implement privacy protection in AI systems, various practical measures can be taken:\n\n1. **Data Anonymization**: Whenever data is collected or processed, anonymizing personal identifiers can help protect personally identifiable information (PII). Techniques such as data masking or pseudonymization can be used to ensure that individuals cannot be identified from the data. \n\n2. **Differential Privacy**: This is a method of adding a controlled amount of noise to the data to make sure that the system does not reveal the confidential information of individuals in its output. It provides strong, provable guarantees of privacy and is being increasingly employed in AI systems.\n\n3. **Securing Data Transmission**: All data in transit must be encrypted to protect it from interception. Similarly, data at rest (stored data) should also be encrypted, and all encryption keys should be securely stored and managed.\n\n4. **Data Minimization**: Collect only the data that is necessary for the system to carry out its functions. This reduces the risk associated with data storage and processing.\n\n5. **Access Controls**: Implement robust access controls to ensure that only authorized personnel can access sensitive data. This includes using secure authentication protocols and setting up user privileges carefully.\n\n6. **Privacy Impact Assessments (PIAs)**: Regular PIAs can help identify potential privacy risks before a system is deployed. The assessments can also inform adjustments to the project for better protection of privacy.\n\n7. **Privacy by Design**: Privacy-protection measures should be integrated into the system during its design phase, not added as an afterthought. With privacy by design, the AI system is built from the ground up to respect privacy.\n\n8. **Regular Audits and Monitoring**: Conducting regular audits and constant monitoring to detect any potential data breaches or other issues that can compromise privacy. This also means monitoring and updates in response to evolving data privacy laws and regulations.\n\n9. **Transparent Data Usage**: Users should be clearly informed about how their data is being collected, used and stored. This is often done through clear and accessible privacy policies.\n\nThese measures, coupled with a robust legal framework, can significantly enhance the ability of AI systems to protect user privacy and build trust among the user base.","x":239,"y":476,"width":1072,"height":942,"color":"6"},
		{"id":"Study Questions/New Questions/AI Governance.md","type":"file","file":"Proofs of Knowledge/Study Questions/New Questions/AI Governance.md","x":-4198,"y":-5063,"width":663,"height":959,"color":"1"},
		{"id":"Engrams/Data Cache/Neurons.md","type":"file","file":"Proofs of Knowledge/Engrams/Data Cache/Neurons.md","x":-5812,"y":-2290,"width":500,"height":503},
		{"id":"Study Questions/Study Questions.md","type":"file","file":"Proofs of Knowledge/Study Questions/Study Questions.md","x":-3199,"y":-7011,"width":940,"height":1060},
		{"id":"05830f97426bcdd0","type":"text","text":"argue how privacy protection could be used in practice","x":-1308,"y":-5512,"width":250,"height":210,"color":"1"},
		{"chat_role":"assistant","id":"248fc31737aa3925","type":"text","text":"To implement privacy protection in AI systems, various practical measures can be taken:\n\n1. **Data Anonymization**: Whenever data is collected or processed, anonymizing personal identifiers can help protect personally identifiable information (PII). Techniques such as data masking or pseudonymization can be used to ensure that individuals cannot be identified from the data. \n\n2. **Differential Privacy**: This is a method of adding a controlled amount of noise to the data to make sure that the system does not reveal the confidential information of individuals in its output. It provides strong, provable guarantees of privacy and is being increasingly employed in AI systems.\n\n3. **Securing Data Transmission**: All data in transit must be encrypted to protect it from interception. Similarly, data at rest (stored data) should also be encrypted, and all encryption keys should be securely stored and managed.\n\n4. **Data Minimization**: Collect only the data that is necessary for the system to carry out its functions. This reduces the risk associated with data storage and processing.\n\n5. **Access Controls**: Implement robust access controls to ensure that only authorized personnel can access sensitive data. This includes using secure authentication protocols and setting up user privileges carefully.\n\n6. **Privacy Impact Assessments (PIAs)**: Regular PIAs can help identify potential privacy risks before a system is deployed. The assessments can also inform adjustments to the project for better protection of privacy.\n\n7. **Privacy by Design**: Privacy-protection measures should be integrated into the system during its design phase, not added as an afterthought. With privacy by design, the AI system is built from the ground up to respect privacy.\n\n8. **Regular Audits and Monitoring**: Conducting regular audits and constant monitoring to detect any potential data breaches or other issues that can compromise privacy. This also means monitoring and updates in response to evolving data privacy laws and regulations.\n\n9. **Transparent Data Usage**: Users should be clearly informed about how their data is being collected, used and stored. This is often done through clear and accessible privacy policies.\n\nThese measures, coupled with a robust legal framework, can significantly enhance the ability of AI systems to protect user privacy and build trust among the user base.","x":-1033,"y":-5016,"width":1072,"height":942,"color":"6"},
		{"id":"Engrams/Engrams.md","type":"file","file":"Proofs of Knowledge/Engrams/Engrams.md","x":-4638,"y":-3313,"width":500,"height":500},
		{"id":"Engrams/Data Cache/How Can Local Governments Safely Use Generative AI-.md","type":"file","file":"Proofs of Knowledge/Engrams/Data Cache/How Can Local Governments Safely Use Generative AI-.md","x":-3542,"y":-4018,"width":500,"height":500},
		{"id":"5eac6f28010884ed","type":"text","text":"## Kneuron Profile\n\n## Name:\nAI Governor Kneuron\n\n## Purpose:\n\nTo identify the best approach for AI systems to solve government governance issues","x":-2748,"y":-4032,"width":479,"height":399,"color":"3"},
		{"chat_role":"assistant","id":"44e1259c8666397e","type":"text","text":"Convincing governments to adopt AI technologies requires effective communication strategies that highlight the benefits, address concerns, and provide practical steps for successful implementation. Here's a plan on how to approach it:\n\n1. **Framing the Argument**: Begin by demonstrating how AI can clearly benefit the government's operations. Include case studies of other governments benefiting from AI, and tie these examples back to the particular government's needs.\n\n2. **Addressing Concerns**: Authorities may have concerns about AI, such as data security, ethical implications, lack of human oversight, and resistance from the workforce. Acknowledge these anxieties and offer practical solutions to counter them. You could include strategies for workforce retraining, robust security measures, and ethical guidelines. \n\n3. **Highlight Economic and Social Impact**: Governments often administer programs with profound social and economic reach. Show how AI can help realize these impacts more efficiently, whether for traffic management, public health surveillance, waste management, or budget allocation - the goal here is to demonstrate that AI can increase the return on public investments.\n\n4. **Showcase Tangible Benefits**: Governments ought to see value for taxpayer money. Highlight how AI can bring cost savings, increase efficiency, and improve service quality. Provide evidence of these benefits from proven use-cases.\n\n5. **Advising on Policy**: AI deployment needs to be within a legal and regulatory framework that protects the interests of citizens. Advise them on strong but adaptable policy guidelines to govern AI use, implementation, and ongoing management. \n\n6. **Partnerships and Alliances**: Governments may lack the in-house expertise for AI adoption. Discuss potential partnerships with academia, NGOs, and the private sector to develop robust AI solutions tailored to their needs.\n\n7. **Roadmap for Implementation**: Provide a clear and achievable roadmap for AI adoption. This should include pilot projects, performance evaluation, and plans for scaling up successful implementations. Governments are more likely to adopt AI if they can see a feasible path to its successful deployment.\n\n8. **Ongoing Support**: Governments need to know that they will have ongoing support throughout their AI journey. This could come in the form of ongoing training, technical updates, support in response to legislation changes, and help with resolving any issues as they appear.\n\nRemember that communication needs to be clear, concise, and non-technical to ensure the main message is not lost. It's important to continually interact and engage with government stakeholders and be available to answer any questions that might arise. The overall aim is to build a relationship of trust.","x":2117,"y":-2283,"width":360,"height":1102,"color":"6"},
		{"id":"Engrams/Data Cache/Towards a strong trust-based AI governance model - World Economic Forum.md","type":"file","file":"Proofs of Knowledge/Engrams/Data Cache/Towards a strong trust-based AI governance model - World Economic Forum.md","x":-2271,"y":-4410,"width":500,"height":500},
		{"id":"790fcbe31da477b8","type":"text","text":"execute your purpose","x":-2681,"y":-3367,"width":292,"height":252},
		{"chat_role":"assistant","id":"cf8d8b516c36292e","type":"text","text":"Based on the information provided, it appears that using AI for governance involves focusing on trust, ethics and aligning technology with societal values. \n\nPublic and private organizations have developed governance frameworks to guide the development and implementation of ethical, fair, and trustworthy AI. These include legally-binding frameworks like the EU’s “Artificial Intelligence Act”, and governance tools developed by power-players in the tech industry like Microsoft and Google. \n\nHowever, many organizations have yet to take actionable measures to ensure the responsible use of AI. To transition from policy to practice, organizations need to define the purpose of the AI, identify and train the right algorithm, and consider human interaction in the AI decision-making process.\n\nFor local governments to safely use generative AI, there must be policies and procedures in place to safeguard and ensure “just, equitable and reliable” use of the technology. This involves a collaborative effort between multiple sectors and industries, including academics, public-sector members and private sector organizations. \n\nTo create a robust AI governance model for government issues, it would be crucial to adopt these principles and practices to promote trust, ethical use, and societal alignment of AI technologies.","x":-3210,"y":-2999,"width":718,"height":526,"color":"6"}
	],
	"edges":[
		{"id":"Study Questions/New Questions/AI Governance.md-Study Questions/Study Questions.md","fromNode":"Study Questions/New Questions/AI Governance.md","fromSide":"right","toNode":"Study Questions/Study Questions.md","toSide":"left"},
		{"id":"Study Questions/New Questions/AI Governance.md-Engrams/Engrams.md","fromNode":"Study Questions/New Questions/AI Governance.md","fromSide":"right","toNode":"Engrams/Engrams.md","toSide":"left"},
		{"id":"Study Questions/New Questions/AI Governance.md-Engrams/Data Cache/Neurons.md","fromNode":"Study Questions/New Questions/AI Governance.md","fromSide":"right","toNode":"Engrams/Data Cache/Neurons.md","toSide":"left"},
		{"id":"Study Questions/New Questions/AI Governance.md-Engrams/Data Cache/How Can Local Governments Safely Use Generative AI-.md","fromNode":"Study Questions/New Questions/AI Governance.md","fromSide":"right","toNode":"Engrams/Data Cache/How Can Local Governments Safely Use Generative AI-.md","toSide":"left"},
		{"id":"Study Questions/New Questions/AI Governance.md-Engrams/Data Cache/Towards a strong trust-based AI governance model - World Economic Forum.md","fromNode":"Study Questions/New Questions/AI Governance.md","fromSide":"right","toNode":"Engrams/Data Cache/Towards a strong trust-based AI governance model - World Economic Forum.md","toSide":"left"},
		{"id":"e2cad11b9bd91867","fromNode":"Engrams/Data Cache/How Can Local Governments Safely Use Generative AI-.md","fromSide":"right","toNode":"790fcbe31da477b8","toSide":"top"},
		{"id":"a0fb79c334c80fff","fromNode":"5eac6f28010884ed","fromSide":"bottom","toNode":"790fcbe31da477b8","toSide":"top"},
		{"id":"7db7eb4e216dbe16","fromNode":"Engrams/Data Cache/Towards a strong trust-based AI governance model - World Economic Forum.md","fromSide":"right","toNode":"790fcbe31da477b8","toSide":"top"},
		{"id":"9c2286ac3856edbe","fromNode":"790fcbe31da477b8","fromSide":"bottom","toNode":"eb3252cd85a5e30e","toSide":"top"},
		{"id":"6edac4f41da4b149","fromNode":"eb3252cd85a5e30e","fromSide":"right","toNode":"51317b1e013a7a14","toSide":"left"},
		{"id":"812530f1dec933f7","fromNode":"51317b1e013a7a14","fromSide":"bottom","toNode":"0ac18a6c7398bb4b","toSide":"top"},
		{"id":"07d19b4570a5e24c","fromNode":"eb3252cd85a5e30e","fromSide":"right","toNode":"7f41382bc3ba2163","toSide":"left"},
		{"id":"20a878139e0f6a3e","fromNode":"7f41382bc3ba2163","fromSide":"bottom","toNode":"dfbbdac3cf67602b","toSide":"top"},
		{"id":"8be8730238971931","fromNode":"eb3252cd85a5e30e","fromSide":"right","toNode":"bfbe9f572b036dc9","toSide":"left"},
		{"id":"6bcca5a1015bdc07","fromNode":"bfbe9f572b036dc9","fromSide":"bottom","toNode":"550d8c5270b08852","toSide":"top"},
		{"id":"7606fb5995778741","fromNode":"0ac18a6c7398bb4b","fromSide":"right","toNode":"acdfd5fe01ad2b30","toSide":"left"},
		{"id":"d1d4f699ed8c4784","fromNode":"acdfd5fe01ad2b30","fromSide":"bottom","toNode":"44e1259c8666397e","toSide":"top"},
		{"id":"c284c88b160907ae","fromNode":"474cb10533f3c519","fromSide":"bottom","toNode":"fe2a033b459a339d","toSide":"top"},
		{"id":"fed2434feb9388ca","fromNode":"44e1259c8666397e","fromSide":"right","toNode":"474cb10533f3c519","toSide":"left"},
		{"id":"23b35ff831a12db7","fromNode":"fe2a033b459a339d","fromSide":"bottom","toNode":"519c26df7ae27e70","toSide":"top"},
		{"id":"0c3a89dbccd01efa","fromNode":"790fcbe31da477b8","fromSide":"bottom","toNode":"1d0170c62969aa48","toSide":"top"},
		{"id":"4d6969612510aed3","fromNode":"790fcbe31da477b8","fromSide":"bottom","toNode":"15c6698a72025a51","toSide":"top"},
		{"id":"c5e871dae4b0f6f3","fromNode":"05830f97426bcdd0","fromSide":"bottom","toNode":"248fc31737aa3925","toSide":"top"},
		{"id":"fcaa8590b4574040","fromNode":"Study Questions/Study Questions.md","fromSide":"right","toNode":"05830f97426bcdd0","toSide":"left"},
		{"id":"9faca5d9716aac75","fromNode":"248fc31737aa3925","fromSide":"bottom","toNode":"1d0170c62969aa48","toSide":"top"},
		{"id":"0575c03eb4939943","fromNode":"790fcbe31da477b8","fromSide":"bottom","toNode":"cf8d8b516c36292e","toSide":"top"}
	]
}